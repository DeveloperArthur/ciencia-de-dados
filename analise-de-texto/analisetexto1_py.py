# -*- coding: utf-8 -*-
"""AnaliseTexto1.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1njEakjxjMIrkCWylkMGWde6rVisaHwdt
"""

import os
import pandas as pd
import numpy as np
import string
import matplotlib.pyplot as plt


def remove_punctuations(text):
    return text.translate(string.punctuation)



df = pd.read_csv("metadata.csv")

df['title'] = df['title'].str.lower()

lixo = '-.,\n'





Text = df['title'].str.replace('/|:;,[^\w\s]',' ')

print("-----------------------------------Numero de titles-------------------------------",Text.count())

Text = Text.drop_duplicates()

print("-----------------------------------Numero de titles-------------------------------",Text.count())
wordsfreq = Text.str.split(expand=True).stack().value_counts()

Wfreq_df = wordsfreq.to_frame()





Wfreq_df.reset_index(level=0, inplace=True)



Wfreq_df.rename(columns={'index':'Tema',
                          0:'Frequencia'},
                 inplace=True)



#limpa as preposições e interjeições
Wfreq_df = Wfreq_df.drop(Wfreq_df[Wfreq_df['Tema'].map(len) < 4].index)




print(Wfreq_df.sort_values(by='Frequencia',ascending=False).head(30))


keys= np.array(['immun', 'vaccin', 'distance', 'asymptomatic',
                'cure', 'drug', 'econo','social','psyc','cell','infec','detec','cloro'])
keysT = np.array(['Imunidade', 'Vacina', 'Distanciamento Social', 'Assintomático',
                'Cura', 'Remédios', 'Economia','Sociedade','Psicológico','Células','Infecção','Detecção','Cloro-quina'])



Theme = pd.DataFrame(columns=['Tema','Frequencia'])

for x in keys:

	Theme = Theme.append(Wfreq_df[Wfreq_df['Tema'].str.contains(x)], ignore_index=True)

for x in keys:
    Theme.loc[(Theme.Tema.str.contains(x)),'Tema_grupo'] = keysT[np.where(keys == x)]

ThemeG = Theme[['Frequencia','Tema_grupo']].groupby(['Tema_grupo']).sum()

print(Theme)
print(ThemeG)
#ThemeG.plot(kind='barh')
#plt.title('Frequência de temas discutidos em 29 mil artigos sobre Coronavirus')
#plt.show()
x = ThemeG.index
y = ThemeG['Frequencia']

fig, ax = plt.subplots()
width = 0.75 # the width of the bars
ind = np.arange(len(y))  # the x locations for the groups
ax.barh(ind, y, width, color="blue")
ax.set_yticks(ind+width/2)
ax.set_yticklabels(x, minor=False)
plt.title('Frequência de temas discutidos em 44 mil artigos sobre Coronavirus')
plt.xlabel('Frequência')
plt.ylabel('Temas')
fig.set_size_inches(18.5, 10.5)
plt.yticks(rotation=45)
for i, v in enumerate(y):
    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')
plt.savefig(os.path.join('plot1.png'), dpi=300, format='png', bbox_inches='tight')

plt.show()

import os
import pandas as pd
import numpy as np
import string
import matplotlib.pyplot as plt


def remove_punctuations(text):
    return text.translate(string.punctuation)



df = pd.read_csv("metadata.csv")

df.columns

df['title'].head(18)

pd.set_option('display.max_colwidth',100)
df['title'] = df['title'].str.lower()
df['title'].head(18)

Text = df['title'].str.replace('()+/|:;,[^\w\s]',' ')
Text.head(15)

print(Text.count())
Text = Text.drop_duplicates()
print(Text.count())

Text

wordsfreq = Text.str.split(expand=True).stack().value_counts()

wordsfreq.head(30)

type(wordsfreq)

#Wfreq_df = wordsfreq.to_frame()
Wfreq_df = pd.DataFrame(wordsfreq, columns=['Frequência'])
#Normalization
Wfreq_df['Teste']=Wfreq_df['Frequência']/Wfreq_df.Frequência.max()
Wfreq_df

Wfreq_df.reset_index(level=0, inplace=True)

Wfreq_df

Wfreq_df.rename(columns={'index':'Tema',
                          0:'Frequencia'},
                 inplace=True)

Wfreq_df

Wfreq_df.head(25)

Wfreq_df = Wfreq_df.drop(Wfreq_df[Wfreq_df['Tema'].map(len) < 4].index)
Wfreq_df = Wfreq_df.drop(Wfreq_df[Wfreq_df['Tema'].isin(['with','from'])].index)
Wfreq_df['Teste'] = Wfreq_df['Frequência']/Wfreq_df.Frequência.max()
Wfreq_df.head(25)

#Wfreq_df.reset_index(level=0, inplace=True)
Wfreq_df.drop(columns=['index'], inplace=True)
Wfreq_df

print(Wfreq_df.sort_values(by='Frequência',ascending=True).head(30))

keys= np.array(['immun', 'vaccin', 'distance', 'asymptomatic',
                'cure', 'drug', 'econo','social','psyc','cell','infec','detec','cloro'])
keysT = np.array(['Imunidade', 'Vacina', 'Distanciamento Social', 'Assintomático',
                'Cura', 'Remédios', 'Economia','Sociedade','Psicológico','Células','Infecção','Detecção','Cloro-quina'])



Theme = pd.DataFrame(columns=['Tema','Frequência'])

for x in keys:

	Theme = Theme.append(Wfreq_df[Wfreq_df['Tema'].str.contains(x)], ignore_index=True)
 
Theme

Theme.head(20)

for x in keys:
    Theme.loc[(Theme.Tema.str.contains(x)),'Tema_grupo'] = keysT[np.where(keys == x)]
Theme

ThemeG = Theme[['Frequência','Tema_grupo']].groupby(['Tema_grupo']).sum()
ThemeG